# üß† AI Knowledge Base Search & Enrichment  
*A lightweight RAG system with document upload, semantic search, and contextual reasoning.*

---

## üöÄ Overview  
This project implements a **Retrieval-Augmented Generation (RAG)** pipeline using **FastAPI** (backend) and **Streamlit** (frontend).  
It allows users to upload text or PDF files, semantically index them into a **Chroma vector database**, and query the knowledge base using natural language.  
Each answer is supported by **citations**, **confidence scores**, and **domain-specific retrieval**, with **DuckDuckGo auto-enrichment** for missing information.

---

## ‚öôÔ∏è Tech Stack
- **Backend:** FastAPI  
- **Frontend:** Streamlit  
- **Vector Store:** ChromaDB  
- **Embeddings:** HuggingFace MiniLM-L6-v2  
- **LLM:** GPT-4o-mini (OpenAI)  
- **Enrichment:** DuckDuckGo Search (ddgs)

---

## üß© Features
- Upload and embed TXT/PDF documents into Chroma collections.  
- Ask natural-language questions across all domains.  
- Retrieve contextual answers with reasoning and confidence.  
- Display citations with similarity scores and snippets.  
- Auto-enrich incomplete responses via DuckDuckGo summaries.

---

## üß∞ How to Run Locally

### 1Ô∏è‚É£ Clone the Repository
```bash
git clone git@github.com:sivaaaa21/ai-knowledge-base.git
cd ai-knowledge-base
```

### 2Ô∏è‚É£ Setup Virtual Environment
```bash
cd backend
python -m venv .venv
.venv\Scripts\activate
```

### 3Ô∏è‚É£ Install Dependencies
```bash
pip install -r requirements.txt
```
### 4Ô∏è‚É£ Add Environment Variables
```bash
OPENAI_API_KEY=your_openai_api_key
```

### 5Ô∏è‚É£ Run Backend
```bash
uvicorn backend.app:app --reload
```
Access API at: http://127.0.0.1:8000

### 6Ô∏è‚É£ Run Frontend
```bash
streamlit run frontend/app.py
```
Access UI at: http://localhost:8501
